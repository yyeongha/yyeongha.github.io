---
title: 논문리뷰_ResNet
categories: [논문리뷰] 
date: 2024-06-03
last_modified_at: 2024-06-05
---

논문출처 : [Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385)

ResNet은 2015년에 개최된 ILSVRC에서 우승을 한 마이크로소프트에서 개발한 알고리즘이다. ResNet은 층층이 쌓인 신경망에 지름길을 만들어 깊이에 따른 성능 저하를 막고 이미지 인식 능력을 크게 향상시킨 획기적인 기술이다.


# 1. Introduction
잔차 학습(Residual Learning)을 통한 심층 신경망 성능 향상

* 기존 심층 신경망의 문제점:
    * Vanishing Gradient (Exploding Gradient, 기울기 소실/폭발): \
    심층 신경망은 깊이가 깊어질수록 기울기 소실/폭발 문제로 인해 학습이 어려워짐.
    * 성능 저하: \
    깊이 증가에 따라 훈련 오류가 증가하여 정확도가 떨어짐 (overfitting(과적합) 때문이 아님).

    ![figure1](https://github.com/yyeongha/yyeongha.github.io/blob/main/assets/img/favicons/2024-06-03-resnet-img/figure1.png?raw=true) *두 그래프는 동일한 조건에서 20개 레이어와 56개 레이어 모델의 실험 결과를 비교한 것이다. \
    오른쪽 그래프(test) 를 보면 56개 레이어 모델이 더 많은 오류를 보이는데, 흥미롭게도 왼쪽 그래프(training) 에서도 56개 레이어 모델의 오류가 더 높다. \
    일반적으로 학습 데이터에서는 모델이 더 복잡할수록 성능이 좋아지는 경향이 있지만, 이 경우에는 그렇지 않은 것을 볼 수 있다. \
    따라서 단순히 과적합 문제라고 보기는 어려우며, 층이 깊어질수록 성능이 저하되는 다른 원인이 있을 가능성을 시사한다.*


* 해결책: 
    * Residual Learning(잔차 학습):
        * 핵심 아이디어: \
        여러 레이어를 쌓아 원하는 함수를 직접 근사하는 대신, 입력값 x에 대한 잔차 함수 F(x) = H(x) - x를 학습. 즉, 원래 함수 H(x)를 F(x) + x로 표현.

        ![residualLearning](https://github.com/yyeongha/yyeongha.github.io/blob/main/assets/img/favicons/2024-06-03-resnet-img/residualLearning.png?raw=true)

        * 장점: \
        잔차 매핑을 최적화하는 것이 더 쉬움. 특히 identity mapping이 최적일 경우 잔차를 0으로 만드는 것이 더 용이.
        * 구현: \
        shortcut connections를 사용하는 feedforward neural networks로 구현 가능 (추가 매개변수나 계산 복잡성 없음).

* 실험 결과:
    * 최적화 용이성: \
    매우 깊은 residual net은 최적화하기 쉬우나, 단순히 레이어를 쌓는 "일반(plain)" net은 깊이 증가 시 훈련 오류 증가.
    * 정확도 향상: \
    깊은 residual net은 깊이를 크게 늘려 정확도를 쉽게 높일 수 있으며, 기존 네트워크보다 훨씬 더 나은 결과 생성.

* 결론:
    * ImageNet 데이터 세트에서 residual net을 사용하여 뛰어난 성능 달성.
    * 잔차 학습 원리는 다양한 문제에 적용 가능함을 시사.

* 핵심: \
잔차 학습은 심층 신경망의 성능 저하 문제를 해결하고 매우 깊은 네트워크 학습을 가능하게 하여 이미지 인식 등 다양한 분야에서 뛰어난 성능을 보임.

![figure1](https://github.com/yyeongha/yyeongha.github.io/blob/main/assets/img/favicons/2024-06-03-resnet-img/figure1.png?raw=true)
![figure2](https://github.com/yyeongha/yyeongha.github.io/blob/main/assets/img/favicons/2024-06-03-resnet-img/figure2.png?raw=true)


# 2. Related Work
## 1) Residual Representations (잔차 표현)
* 잔차 벡터 활용의 이점: 
    * 효과적인 특징 표현: \
    잔차 벡터는 이미지의 세부적인 특징을 더욱 효과적으로 표현할 수 있게 해줍니다. 이는 이미지 검색이나 분류에서 더 정확한 결과를 얻는 데 도움이 됩니다.
    * 처리 속도 향상: \
    잔차 정보만 처리하면 되므로 전체 이미지를 처리하는 것보다 빠르게 작업을 수행할 수 있습니다. 특히, 다중 격자 방법에서는 잔차 정보를 활용하여 이미지 처리 속도를 크게 향상시킬 수 있습니다.
    * 결과 향상: \
    잔차 정보를 활용하여 이미지의 품질을 향상시킬 수 있습니다. 다중 격자 방법에서는 잔차 정보를 처리하여 이미지를 더욱 선명하게 만들 수 있으며, 이미지 인식 분야에서는 잔차 벡터를 활용하여 더 정확한 검색 및 분류 결과를 얻을 수 있습니다.


## 2) Shortcut Connections
Shortcut Connections 이란? \
-> 깊이 있는 신경망 학습을 위한 지름길!

* ResNet의 특징: 
    * 게이트 없는 identity shortcut connection: \
    ResNet은 게이트 없이 모든 정보를 항상 shortcut을 통해 전달하고, 추가적인 잔차 함수만 학습한다.
    * 깊이 증가에 따른 성능 향상: \
    100개 이상의 층을 쌓아도 정확도가 향상되는 것을 보여주었으며, 이는 Highway Networks보다 뛰어난 성능이다.

* 비유를 통해 이해하기:
    * Highway Networks: \
    고속도로에 요금소(게이트)가 있어서, 차량 통행량을 조절하는 것과 같다.
    * ResNet: \
    고속도로에 요금소가 없어서, 모든 차량이 자유롭게 통행하는 것과 같다.


# 3. Deep Residual Learning
## 3.1. Residual Learning
* 기존 가정 \
: 층(layer)을 많이 쌓을수록(깊이가 깊어질수록) 신경망이 더 복잡한 함수를 잘 학습할 수 있다고 생각했다.

* 문제점 \
: 하지만 실제로는 층을 무작정 쌓는다고 해서 더 좋은 결과가 나오지 않았다. 오히려 너무 깊어지면 성능이 떨어지는 문제가 발생했다. 이는 층을 쌓을 때 단순히 이전 층의 결과값을 다음 층에 전달하는 것이 아니라, 각 층이 원래 목표로 했던 함수(H(x))를 학습하는 데 어려움을 겪기 때문이다. 특히, 각 층이 아무런 변화를 일으키지 않는 함수, 즉 입력값을 그대로 출력값으로 내보내는 항등 함수(identity mapping)를 학습하는 것조차 어려웠다.

* 해결책 \
: 이 문제를 해결하기 위해 본 논문은 잔차 학습(residual learning)이라는 방법을 제안한다. 각 층이 원래 함수(H(x))를 직접 학습하는 대신, 입력값(x)과 출력값(H(x))의 차이, 즉 잔차(residual) 함수 F(x) = H(x) - x를 학습하도록 한다. 잔차 함수는 원래 함수보다 훨씬 단순한 형태이기 때문에 학습하기 쉽다. 특히, 최적의 함수가 항등 함수에 가까운 경우에는 잔차 함수의 값이 0에 가까워지므로 학습이 더욱 쉬워진다.

* 실험 결과 \
: 실제 실험 결과, 잔차 학습을 통해 훈련된 신경망은 층이 매우 많아도 안정적으로 학습되었고, 기존 방법보다 훨씬 좋은 성능을 보였다. 이는 잔차 학습이 깊은 신경망을 효과적으로 학습하는 데 유용한 방법임을 시사한다.

## 3.2. Identity Mapping by Shortcuts
잔차 학습(Residual Learning)과 Shortcut Connection으로 더 깊고 효율적인 신경망 구축
* 핵심 아이디어:
    * 잔차 학습 (Residual Learning): \
    각 신경망 층에서 입력값을 그대로 다음 층으로 전달하는 shortcut connection을 추가하여, 각 층은 입력값과 출력값의 차이인 잔차 함수(residual function)를 학습한다. 잔차 함수 학습이 더 쉽기 때문에 깊은 신경망도 효과적으로 학습 가능하다.
    * Shortcut Connection: \
    추가적인 매개변수나 계산량 증가 없이 층 사이의 정보 흐름을 원활하게 한다. 입력과 출력의 크기가 다른 경우에도 사용 가능하며, 이미지 처리에서도 잔차 값을 더하여 다음 층으로 전달하는 방식으로 활용된다.

* 장점:
    * 깊은 신경망 학습 용이성: \
    잔차 함수 학습을 통해 깊은 신경망에서 발생하는 기울기 소실 문제를 완화하고, 더 깊은 네트워크를 효과적으로 학습할 수 있다.
    * 유연성: \
    입력과 출력의 크기가 다른 경우에도 shortcut connection을 사용할 수 있어 다양한 신경망 구조에 적용 가능하다.
    * 효율성: \
    shortcut connection은 추가적인 매개변수나 계산량을 늘리지 않아 효율적인 학습이 가능하다.

* 주의 사항: \
잔차 함수가 한 개의 층으로만 구성될 경우 잔차 학습의 장점이 나타나지 않으므로, 여러 개의 층으로 구성하는 것이 좋다.


## 3.3. Network Architectures
* ResNet의 핵심 아이디어: \
ResNet은 깊은 신경망의 성능을 향상시키기 위해 shortcut connection이라는 지름길을 추가한 모델이다. 이 지름길을 통해 입력값을 출력값에 더하여 다음 층으로 전달함으로써, 층이 많아져도 성능이 떨어지지 않도록 한다.

* ResNet의 특징:
    * VGGNet 기반 설계: \
    ResNet은 기존의 VGGNet 모델을 기반으로 설계되었지만, 복잡한 연산을 줄여 효율성을 높였다.
    * Shortcut Connection: \
    입력값과 출력값을 더하여 다음 층으로 전달하는 것이 핵심이다. 이때 입력값과 출력값의 크기가 다를 경우, 출력값에 0을 채우거나 1x1 컨볼루션 연산을 통해 크기를 맞춘다.
    * 깊이 있는 신경망 학습 가능: \
    Shortcut connection을 통해 층을 깊게 쌓아도 성능이 떨어지지 않도록 하여, 다양한 이미지 인식 문제에서 뛰어난 성능을 보여준다.

## 3.4. Implementation
ImageNet 데이터셋에 대한 ResNet 모델 구현은 기존 연구의 방식을 따른다.

* 훈련 단계:
    1. 이미지 크기 조정: \
    먼저, 이미지의 짧은 쪽 길이를 256에서 480 사이의 값으로 무작위로 선택하여 이미지 크기를 조정한다. 이는 다양한 크기의 이미지를 학습에 사용하여 모델의 성능을 높이는 데 도움이 된다.
    2. 이미지 자르기: \
    크기가 조정된 이미지에서 224x224 크기의 부분을 무작위로 잘라내거나, 이미지를 수평으로 뒤집은 후 잘라낸다. 그리고 각 픽셀에서 평균값을 빼는 전처리를 수행한다.
    3. 색상 조정: \
    이미지의 색상을 약간씩 조정하여 다양한 색상 환경에서도 모델이 잘 작동하도록 한다.
    4. Batch Normalization(BN): \
    각 컨볼루션 연산 후에 배치 정규화를 적용하여 학습 과정을 안정화하고 성능을 향상시킨다.
    5. weight decay(가중치 초기화) 및 훈련: \
    신경망의 가중치를 초기화하고, 준비된 데이터를 사용하여 처음부터 모델을 학습한다. \
    학습에는 SGD(확률적 경사 하강법)라는 최적화 알고리즘을 사용하고, 미니 배치 크기는 256으로 설정한다. \
    학습률은 0.1에서 시작하여 오류가 줄어들지 않으면 10으로 나누어 줄여나가며, 최대 600,000번까지 반복하여 학습한다.

* 테스트 단계:
    * 10-crop 테스트: \
    이미지를 10개의 작은 부분으로 나누어 각 부분에 대한 예측 결과를 평균하여 모델의 성능을 평가한다.
    * 다중 척도 테스트: \
    이미지 크기를 다양하게 조절하여 여러 크기에서 예측 결과를 얻은 후, 이를 평균하여 최종 결과를 얻는다. 이는 다양한 크기의 객체를 더 잘 인식하는 데 도움이 된다.


# 4. Experiments
![table2]()
![table4]()
![table5]()





















---